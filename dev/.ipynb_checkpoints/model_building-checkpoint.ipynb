{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMNI Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmni_path = os.path.abspath(os.path.join('..'))\n",
    "if hmni_path not in sys.path:\n",
    "    sys.path.append(hmni_path+\"\\\\hmni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_names = pd.read_csv('name_pairs.txt', sep=\",\", names=['name_a', 'name_b'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13291</th>\n",
       "      <td>Petka</td>\n",
       "      <td>Petrusha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>Larre</td>\n",
       "      <td>Lorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>Luanne</td>\n",
       "      <td>Louann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>Lexa</td>\n",
       "      <td>Cass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>Jenn</td>\n",
       "      <td>Jen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>Luis</td>\n",
       "      <td>Luisinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>Antonieczka</td>\n",
       "      <td>Toska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>Hanna</td>\n",
       "      <td>Ann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>Pamela</td>\n",
       "      <td>Pam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12020</th>\n",
       "      <td>Morteza</td>\n",
       "      <td>Mori</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name_a    name_b\n",
       "13291        Petka  Petrusha\n",
       "8436         Larre     Lorre\n",
       "9396        Luanne    Louann\n",
       "8758          Lexa      Cass\n",
       "6912          Jenn       Jen\n",
       "9460          Luis  Luisinho\n",
       "1030   Antonieczka     Toska\n",
       "5644         Hanna       Ann\n",
       "12988       Pamela       Pam\n",
       "12020      Morteza      Mori"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_names.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import syllable_tokenizer\n",
    "\n",
    "from abydos.distance import (IterativeSubString, BISIM, DiscountedLevenshtein, Prefix, LCSstr, MLIPNS, Strcmp95,\n",
    "MRA, Editex, SAPS, FlexMetric, JaroWinkler, HigueraMico, Sift4, Eudex, ALINE, Covington, PhoneticEditDistance)\n",
    "\n",
    "from abydos.phonetic import PSHPSoundexFirst, Ainsworth\n",
    "pshp_soundex_first = PSHPSoundexFirst()\n",
    "pe = Ainsworth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = IterativeSubString()\n",
    "bisim = BISIM()\n",
    "dlev = DiscountedLevenshtein()\n",
    "prefix = Prefix()\n",
    "lcs = LCSstr()\n",
    "mlipns = MLIPNS()\n",
    "strcmp95 = Strcmp95()\n",
    "mra = MRA()\n",
    "editex = Editex()\n",
    "saps = SAPS()\n",
    "flexmetric = FlexMetric()\n",
    "jaro = JaroWinkler(mode='Jaro')\n",
    "higuera_mico = HigueraMico()\n",
    "sift4 = Sift4()\n",
    "eudex = Eudex()\n",
    "aline = ALINE()\n",
    "covington = Covington()\n",
    "phonetic_edit = PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [iss, bisim, dlev, prefix, lcs, mlipns, strcmp95, mra, editex, saps, flexmetric, jaro, higuera_mico, sift4, eudex,\n",
    "         aline, covington, phonetic_edit]\n",
    "\n",
    "algo_names = ['iterativesubstring', 'bisim', 'discountedlevenshtein', 'prefix', 'lcsstr', 'mlipns', 'strcmp95', 'mra',\n",
    "              'editex', 'saps', 'flexmetric', 'jaro', 'higueramico', 'sift4', 'eudex', 'aline', 'covington',\n",
    "              'phoneticeditdistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos.phones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ipa(name_a, name_b):\n",
    "    feat1 = ipa_to_features(pe.encode(name_a))\n",
    "    feat2 = ipa_to_features(pe.encode(name_b))\n",
    "    score = sum(cmp_features(f1, f2) for f1, f2 in zip(feat1, feat2))/len(feat1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    if len(df.columns)==3:\n",
    "        df.columns=['a', 'b', 'target']\n",
    "    elif len(df.columns)==2:\n",
    "        df.columns=['a', 'b']\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]: 'a', df.columns[1]: 'b' })\n",
    "        \n",
    "    df['name_a'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['a']).lower().strip()), axis=1)\n",
    "    df['name_b'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['b']).lower().strip()), axis=1)\n",
    "    \n",
    "    df['syll_a'] = df.apply(lambda row: syllable_tokenizer.syllables(row.name_a), axis=1)\n",
    "    df['syll_b'] = df.apply(lambda row: syllable_tokenizer.syllables(row.name_b), axis=1)\n",
    "    \n",
    "    df['partial'] = df.apply(lambda row: fuzz.partial_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    df['tkn_sort'] = df.apply(lambda row: fuzz.token_sort_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    df['tkn_set'] = df.apply(lambda row: fuzz.token_set_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    \n",
    "    df['sum_ipa'] = df.apply(lambda row: sum_ipa(row.name_a, row.name_b), axis=1)\n",
    "    \n",
    "    df['pshp_soundex_first'] = df.apply(\n",
    "        lambda row: 1 if pshp_soundex_first.encode(row.name_a)==pshp_soundex_first.encode(row.name_b) else 0, axis=1)\n",
    "    \n",
    "    for i, algo in enumerate(algos):\n",
    "            df[algo_names[i]] = df.apply(lambda row: algo.sim(row.name_a, row.name_b), axis=1)\n",
    "            \n",
    "    df.drop(['syll_a', 'syll_b'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused featurize code\n",
    "'''\n",
    "def removesuffix(name):\n",
    "    # high-frequency suffixes\n",
    "    suffixes =['acska','ander','andra','annah','annes','anuel','arina','athan','cilla','cillo','delia','echka',\n",
    "               'ecita','ecito','eczek','eczka','ediah','elina','eline','eniek','erick','erina','essie','ester',\n",
    "               'henka','ienka','illie','islav','lbert','lenka','linda','linha','lphia','nchik','nette','ninha',\n",
    "               'ochka','olina','oncho','onnie','oshka''oslav','rance','rence','rilla','rinda','risse','slava',\n",
    "               'stina','stine','tenka','ushka','ustin','yinka','yusha','zuela','zuelo','akun','alle','anda',\n",
    "               'ande','anka','anna','anne','bert','chan','chen','chka','chuk','ciek','cita','citp','czek','czka',\n",
    "               'elia','ella','elle','ence','enia','enka','enki','enne','erre','erry','etta','ette','iana','illa',\n",
    "               'ille','illo','illy','imir','inda','inha','inho','inka','inyu','isse','lava','lein','lina','line',\n",
    "               'llie','ncho','ndra','nnie','oche','omir','onne','rick','rina','shka','slav','ssie','ster','tina',\n",
    "               'tine','uela','uelo','uina','usha','usia','yika','ale','ana','ane','ari','chk','cho','cia','csi',\n",
    "               'czo','ela','ele','ell','ena','ene','ert','eta','ete','han','hka','iah','ica','ick','ico','ika',\n",
    "               'ina','ine','ino','isa','ita','ito','lav','lia','lie','lka','lki','lla','lle','lly','mir','nce',\n",
    "               'nda','nha','nia','nie','njo','nka','nna','nne','nny','onk','ora','rre','rry','sha','shk','sia',\n",
    "               'sie','ska','ski','sku','son','sse','tta','tte','ush','yok','zek','zka','ah','am','an','as','av',\n",
    "               'ca','ce','ck','da','de','do','dy','ek','el','en','er','es','et','ey','ge','ha','ho','ia','ic',\n",
    "               'ie','ig','ik','in','is','ja','ke','ko','la','le','ll','lo','na','ne','ni','on','or','ot','ra',\n",
    "               're','ri','ry','sa','se','si','ta','te','to','un','us','ya','a','e','i','l','o','y']   \n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        if name.endswith(suffix):\n",
    "            if len(name)>len(suffix)+1:\n",
    "                return name[:-(len(suffix))]\n",
    "    return name\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused featurize code\n",
    "'''\n",
    "# Remove frequent prefix/suffix\n",
    "df['stemmed_a'] = df.apply(lambda row: removesuffix(row.name_a), axis=1)\n",
    "df['stemmed_b'] = df.apply(lambda row: removesuffix(row.name_b), axis=1)\n",
    "\n",
    "# Remove Vowels\n",
    "df['consonant_a'] = df.apply(lambda row: re.sub(\"[aeiouAEIOU]\", \"\", row.name_a), axis=1)  \n",
    "df['consonant_b'] = df.apply(lambda row: re.sub(\"[aeiouAEIOU]\", \"\", row.name_b), axis=1)\n",
    "\n",
    "for i, metric in enumerate(dist_metrics):\n",
    "    print(type(metric))\n",
    "    try:\n",
    "        df[dist_names[i]+'_stem'] = df.apply(lambda row: metric.sim(row.name_a, row.name_b), axis=1)\n",
    "    except:\n",
    "         continue\n",
    "\n",
    "for i, metric in enumerate(dist_metrics):\n",
    "    print(type(metric))\n",
    "    try:\n",
    "        df[dist_names[i]+'_cons'] = df.apply(lambda row: metric.sim(row.name_a, row.name_b), axis=1)\n",
    "    except:\n",
    "         continue\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Class\n",
    "alt_names['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use combinatorics to generate negative class\n",
    "all_names = alt_names.loc[:, 'name_a':'name_b'].values.tolist()\n",
    "unique_names = list(set([item for items in all_names for item in items]))\n",
    "alt_pairs = list(zip(alt_names.name_a, alt_names.name_b))+ list(zip(alt_names.name_b, alt_names.name_a))\n",
    "comb = list(combinations(unique_names, 2))\n",
    "non_alt = list(set(comb) - set(alt_pairs))\n",
    "# Undersample the negative class for 1:4 class imbalance instead of 1:1000 extreme class imbalance\n",
    "non_alt = pd.DataFrame(random.choices(non_alt, k=70040), columns=['name_a', 'name_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive class ratio 1:4\n"
     ]
    }
   ],
   "source": [
    "print('positive class ratio 1:{}'.format(int(len(non_alt)/len(alt_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61447</th>\n",
       "      <td>Simon</td>\n",
       "      <td>Filipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22853</th>\n",
       "      <td>Serene</td>\n",
       "      <td>Roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18118</th>\n",
       "      <td>Basil</td>\n",
       "      <td>Ernesto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34206</th>\n",
       "      <td>Nastasya</td>\n",
       "      <td>Zackery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26926</th>\n",
       "      <td>Tice</td>\n",
       "      <td>Jamie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62061</th>\n",
       "      <td>Frejs</td>\n",
       "      <td>Becca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46320</th>\n",
       "      <td>Little</td>\n",
       "      <td>William</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>Mehdi</td>\n",
       "      <td>Chami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>Michal</td>\n",
       "      <td>Karol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507</th>\n",
       "      <td>Trisha</td>\n",
       "      <td>Rob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name_a   name_b\n",
       "61447     Simon   Filipe\n",
       "22853    Serene  Roberta\n",
       "18118     Basil  Ernesto\n",
       "34206  Nastasya  Zackery\n",
       "26926      Tice    Jamie\n",
       "62061     Frejs    Becca\n",
       "46320    Little  William\n",
       "5617      Mehdi    Chami\n",
       "4507     Michal    Karol\n",
       "16507    Trisha      Rob"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_alt.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Negative Class\n",
    "non_alt['target'] = 0\n",
    "df = pd.concat([alt_names, non_alt])\n",
    "non_alt = None\n",
    "alt_names = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = featurize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>iterativesubstring</th>\n",
       "      <th>bisim</th>\n",
       "      <th>discountedlevenshtein</th>\n",
       "      <th>prefix</th>\n",
       "      <th>lcsstr</th>\n",
       "      <th>mlipns</th>\n",
       "      <th>strcmp95</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>covington</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Eliza</td>\n",
       "      <td>Louetta</td>\n",
       "      <td>1</td>\n",
       "      <td>eliza</td>\n",
       "      <td>louetta</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.174860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630476</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.861765</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.619816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13578</th>\n",
       "      <td>Quilla</td>\n",
       "      <td>Aquilla</td>\n",
       "      <td>1</td>\n",
       "      <td>quilla</td>\n",
       "      <td>aquilla</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>100</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.818007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>Terus</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>0</td>\n",
       "      <td>terus</td>\n",
       "      <td>ursula</td>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.738710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.152574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.618280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>Mariaisabel</td>\n",
       "      <td>Maribel</td>\n",
       "      <td>1</td>\n",
       "      <td>mariaisabel</td>\n",
       "      <td>maribel</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0.466276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.675960</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.572980</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16017</th>\n",
       "      <td>Bridey</td>\n",
       "      <td>Con</td>\n",
       "      <td>0</td>\n",
       "      <td>bridey</td>\n",
       "      <td>con</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298387</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.427419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 a        b  target       name_a   name_b  partial  tkn_sort  \\\n",
       "4184         Eliza  Louetta       1        eliza  louetta       65        62   \n",
       "13578       Quilla  Aquilla       1       quilla  aquilla       93        88   \n",
       "4264         Terus   Ursula       0        terus   ursula       62        14   \n",
       "10270  Mariaisabel  Maribel       1  mariaisabel  maribel       79        75   \n",
       "16017       Bridey      Con       0       bridey      con       43         0   \n",
       "\n",
       "       tkn_set   sum_ipa  pshp_soundex_first  iterativesubstring     bisim  \\\n",
       "4184        62  0.600000                   0            0.000000  0.214286   \n",
       "13578      100  0.723502                   0            0.961538  0.785714   \n",
       "4264        14  0.738710                   0            0.000000  0.250000   \n",
       "10270       80  0.466276                   1            0.933333  0.590909   \n",
       "16017        0  0.298387                   0            0.000000  0.000000   \n",
       "\n",
       "       discountedlevenshtein    prefix    lcsstr  mlipns  strcmp95       mra  \\\n",
       "4184                0.174860  0.000000  0.142857     0.0  0.630476  0.666667   \n",
       "13578               0.818007  0.000000  0.857143     0.0  0.952381  0.833333   \n",
       "4264                0.152574  0.000000  0.166667     0.0  0.625556  0.666667   \n",
       "10270               0.675960  0.571429  0.363636     0.0  0.927273  0.833333   \n",
       "16017               0.051337  0.000000  0.000000     0.0  0.000000  0.000000   \n",
       "\n",
       "         editex      saps  flexmetric      jaro  higueramico     sift4  \\\n",
       "4184   0.500000  0.000000    0.528571  0.561905     0.190476  0.285714   \n",
       "13578  0.857143  0.590909    0.857143  0.952381     0.857143  0.857143   \n",
       "4264   0.250000  0.000000    0.283333  0.588889     0.261905  0.500000   \n",
       "10270  0.727273  0.516129    0.636364  0.878788     0.572980  0.636364   \n",
       "16017  0.166667  0.000000    0.241667  0.000000     0.000000  0.000000   \n",
       "\n",
       "          eudex     aline  covington  phoneticeditdistance  \n",
       "4184   0.861765  0.348485   0.533898              0.619816  \n",
       "13578  0.800000  0.909091   0.900000              0.857143  \n",
       "4264   0.584314  0.416667   0.554545              0.618280  \n",
       "10270  0.847059  0.575472   0.787356              0.636364  \n",
       "16017  0.857843  0.243333   0.325581              0.427419  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target\n",
    "X = df.drop('target',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOML Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tpot import TPOTClassifier  # conda install -c conda-forge tpot xgboost dask dask-ml scikit-mdr skrebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pipeline_optimizer = TPOTClassifier(\n",
    "        scoring = 'f1', \n",
    "        generations=100,\n",
    "        verbosity=2,\n",
    "        n_jobs=-1   # Utilizes all available CPU cores\n",
    "        ) \n",
    "pipeline_optimizer.fit(X_train.drop(['a', 'b', 'name_a', 'name_b'],1), y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipeline_optimizer.score(X_test.drop(['a', 'b', 'name_a', 'name_b'], 1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base-Model 1: Exported TPOT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_1(X_train, y_train, X_test, export=False):\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MaxAbsScaler(),\n",
    "        MinMaxScaler(),\n",
    "        RandomForestClassifier(\n",
    "            bootstrap=False,\n",
    "            criterion=\"gini\",\n",
    "            max_features=0.25,\n",
    "            min_samples_leaf=1,\n",
    "            min_samples_split=4,\n",
    "            n_estimators=100)\n",
    "    )\n",
    "    exported_pipeline.fit(X_train, y_train)\n",
    "    if export==True:\n",
    "        return exported_pipeline\n",
    "    else:\n",
    "        y_pred = exported_pipeline.predict_proba(X_test)\n",
    "        return [p[1] for p in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base-Model 2: Deep LSTM Siamese Network\n",
    "###   Modified from repo: https://github.com/dhwajraj/deep-siamese-text-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf  # tensorflow >= 1.11,< 2.0\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_helpers import InputHelper\n",
    "from siamese_network import SiameseLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_2(X_train, y_train, X_test, export=False):\n",
    "    \n",
    "    # Train Model\n",
    "    embedding_dim = 300  # Dimensionality of character embedding\n",
    "    dropout_keep_prob = 0.8  # Dropout keep probability\n",
    "    hidden_units = 50\n",
    "    batch_size = 64\n",
    "    num_epochs = 300  # Number of training epochs\n",
    "    evaluate_every = 1000  # Evaluate model on dev set after this many steps\n",
    "    max_document_length = 15\n",
    "    out_dir = os.getcwd()+'\\\\'  # where to save exported models\n",
    "\n",
    "    inpH = InputHelper()\n",
    "    train_set, dev_set, vocab_processor, sum_no_of_batches = \\\n",
    "        inpH.get_datasets(\n",
    "        X_train[['name_a', 'name_b']],\n",
    "        y_train,\n",
    "        max_document_length=max_document_length,\n",
    "        percent_dev=10,\n",
    "        batch_size=64)\n",
    "\n",
    "\n",
    "    # print('starting graph def')\n",
    "    graph = tf.Graph()\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        # print('started session')\n",
    "        with sess.as_default():\n",
    "            siameseModel = SiameseLSTM(\n",
    "                sequence_length=max_document_length,\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_dim,\n",
    "                hidden_units=hidden_units,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "            # Define Training procedure\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "            # print('initialized siameseModel object')\n",
    "\n",
    "        grads_and_vars = optimizer.compute_gradients(siameseModel.loss)\n",
    "        tr_op_set = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "        # print('defined training_ops')\n",
    "        \n",
    "        if export==True:\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=100)\n",
    "            # Write vocabulary\n",
    "            vocab_processor.save(os.path.join(out_dir, 'vocab'))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x1_batch, x2_batch, y_batch):\n",
    "            # A single training step\n",
    "            if random.random() > 0.5:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x1_batch,\n",
    "                    siameseModel.input_x2: x2_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: dropout_keep_prob,\n",
    "                }\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x2_batch,\n",
    "                    siameseModel.input_x2: x1_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: dropout_keep_prob,\n",
    "                }\n",
    "            (_, step, loss, accuracy, dist, sim) = \\\n",
    "                sess.run([tr_op_set, global_step, siameseModel.loss, siameseModel.accuracy,\n",
    "                          siameseModel.distance, siameseModel.temp_sim], feed_dict)\n",
    "\n",
    "        def dev_step(x1_batch, x2_batch, y_batch):\n",
    "            # A single training step\n",
    "            if random.random() > 0.5:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x1_batch,\n",
    "                    siameseModel.input_x2: x2_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: 1.0,\n",
    "                }\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x2_batch,\n",
    "                    siameseModel.input_x2: x1_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: 1.0,\n",
    "                }\n",
    "            (step, loss, accuracy, sim) = \\\n",
    "                sess.run([global_step, siameseModel.loss, siameseModel.accuracy,\n",
    "                          siameseModel.temp_sim], feed_dict)\n",
    "            return accuracy\n",
    "\n",
    "        # Generate batches\n",
    "        batches = inpH.batch_iter(list(zip(train_set[0], train_set[1],\n",
    "                                           train_set[2])), batch_size, num_epochs)\n",
    "        max_validation_acc = 0.0\n",
    "        for nn in range(sum_no_of_batches * num_epochs):\n",
    "            batch = next(batches)\n",
    "            if len(batch) < 1:\n",
    "                continue\n",
    "            (x1_batch, x2_batch, y_batch) = zip(*batch)\n",
    "            if len(y_batch) < 1:\n",
    "                continue\n",
    "            train_step(x1_batch, x2_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            sum_acc = 0.0\n",
    "            if current_step % evaluate_every == 0:\n",
    "                dev_batches = inpH.batch_iter(list(zip(dev_set[0], dev_set[1], dev_set[2])), batch_size, 1)\n",
    "                for db in dev_batches:\n",
    "                    if len(db) < 1:\n",
    "                        continue\n",
    "                    (x1_dev_b, x2_dev_b, y_dev_b) = zip(*db)\n",
    "                    if len(y_dev_b) < 1:\n",
    "                        continue\n",
    "                    acc = dev_step(x1_dev_b, x2_dev_b, y_dev_b)\n",
    "                    sum_acc = sum_acc + acc\n",
    "            if sum_acc > max_validation_acc:\n",
    "                max_validation_acc = sum_acc\n",
    "            \n",
    "                if export==True:\n",
    "                    # save model\n",
    "                    saver.save(sess, out_dir, global_step=current_step)\n",
    "                    tf.train.write_graph(sess.graph.as_graph_def(), out_dir, 'siamese_network.pb', as_text=False)\n",
    "                \n",
    "                # print('model {} with sum_accuracy={}'.format(nn, max_validation_acc))     \n",
    "        if export==True:\n",
    "            return\n",
    "        \n",
    "        # RUN OOF INFERENCE\n",
    "        x1_temp= np.asarray(X_test['name_a'].tolist())\n",
    "        x2_temp= np.asarray(X_test['name_b'].tolist())\n",
    "        \n",
    "        x1 = np.asarray(list(vocab_processor.transform(x1_temp)))\n",
    "        x2 = np.asarray(list(vocab_processor.transform(x2_temp)))\n",
    "\n",
    "        (predictions, sim) = sess.run([siameseModel.distance, siameseModel.temp_sim], {\n",
    "                siameseModel.input_x1: x1,\n",
    "                siameseModel.input_x2: x2,\n",
    "                siameseModel.dropout_keep_prob: 1.0,\n",
    "            })\n",
    "                \n",
    "        sim = predictions.tolist()\n",
    "        sim = [1-x for x in sim]\n",
    "        # print(sim)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "completed fold 1 of 10\n",
      "completed fold 2 of 10\n",
      "completed fold 3 of 10\n",
      "completed fold 4 of 10\n",
      "completed fold 5 of 10\n",
      "completed fold 6 of 10\n",
      "completed fold 7 of 10\n",
      "completed fold 8 of 10\n",
      "completed fold 9 of 10\n",
      "completed fold 10 of 10\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Folds cross-validator\n",
    "meta_training = pd.DataFrame()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    oof_pred = X_test[['name_a', 'name_b']]\n",
    "    \n",
    "    oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'name_a', 'name_b'], 1),\n",
    "                                      y_train,\n",
    "                                      X_test.drop(['a', 'b', 'name_a', 'name_b'], 1))\n",
    "\n",
    "    oof_pred['siamese_sim'] = base_model_2(X_train[['name_a', 'name_b']],\n",
    "                                      y_train,\n",
    "                                      X_test[['name_a', 'name_b']])\n",
    "    \n",
    "    oof_pred['target'] = y_test.tolist()\n",
    "    \n",
    "    print('completed fold {} of 10'.format(fold))\n",
    "    fold += 1\n",
    "\n",
    "    meta_training = meta_training.append(oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>siamese_sim</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51016</th>\n",
       "      <td>kizza</td>\n",
       "      <td>wally</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8483</th>\n",
       "      <td>lavinia</td>\n",
       "      <td>lavina</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43206</th>\n",
       "      <td>lyuba</td>\n",
       "      <td>lyde</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.176726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>brano</td>\n",
       "      <td>branko</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>cathy</td>\n",
       "      <td>vlatko</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52371</th>\n",
       "      <td>carly</td>\n",
       "      <td>gosia</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.018706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23063</th>\n",
       "      <td>samuel</td>\n",
       "      <td>andrzej</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.054783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16070</th>\n",
       "      <td>svetlana</td>\n",
       "      <td>patte</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>mihajlo</td>\n",
       "      <td>dave</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11338</th>\n",
       "      <td>mil</td>\n",
       "      <td>milomir</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name_a   name_b  predict_proba  siamese_sim  target\n",
       "51016     kizza    wally       0.025000     0.012512       0\n",
       "8483    lavinia   lavina       1.000000     0.876683       1\n",
       "43206     lyuba     lyde       0.455000     0.176726       0\n",
       "2143      brano   branko       1.000000     0.994689       1\n",
       "5562      cathy   vlatko       0.020000     0.000949       0\n",
       "52371     carly    gosia       0.093333     0.018706       0\n",
       "23063    samuel  andrzej       0.003333     0.054783       0\n",
       "16070  svetlana    patte       0.061667     0.000016       0\n",
       "5608    mihajlo     dave       0.000000     0.000226       0\n",
       "11338       mil  milomir       1.000000     0.995796       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_training.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = featurize(meta_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>siamese_sim</th>\n",
       "      <th>target</th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>iterativesubstring</th>\n",
       "      <th>bisim</th>\n",
       "      <th>discountedlevenshtein</th>\n",
       "      <th>prefix</th>\n",
       "      <th>lcsstr</th>\n",
       "      <th>mlipns</th>\n",
       "      <th>strcmp95</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>covington</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>abbe</td>\n",
       "      <td>tabitha</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.882813</td>\n",
       "      <td>1</td>\n",
       "      <td>abbe</td>\n",
       "      <td>tabitha</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.335921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.204762</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.781373</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.529954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>abdolreza</td>\n",
       "      <td>aboli</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.929013</td>\n",
       "      <td>1</td>\n",
       "      <td>abdolreza</td>\n",
       "      <td>aboli</td>\n",
       "      <td>71</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.520491</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.343254</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.886765</td>\n",
       "      <td>0.442553</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.551971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>abisola</td>\n",
       "      <td>bisi</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.225748</td>\n",
       "      <td>1</td>\n",
       "      <td>abisola</td>\n",
       "      <td>bisi</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.69076</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.472095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.821078</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.552995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>aboli</td>\n",
       "      <td>abdollah</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.948756</td>\n",
       "      <td>1</td>\n",
       "      <td>aboli</td>\n",
       "      <td>abdollah</td>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566334</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.938235</td>\n",
       "      <td>0.529545</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.608871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>aca</td>\n",
       "      <td>aleks</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.932809</td>\n",
       "      <td>1</td>\n",
       "      <td>aca</td>\n",
       "      <td>aleks</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.233956</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.989216</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.512903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            a         b  predict_proba  siamese_sim  target     name_a  \\\n",
       "26       abbe   tabitha       0.046667     0.882813       1       abbe   \n",
       "45  abdolreza     aboli       0.835000     0.929013       1  abdolreza   \n",
       "67    abisola      bisi       0.958333     0.225748       1    abisola   \n",
       "72      aboli  abdollah       0.916667     0.948756       1      aboli   \n",
       "82        aca     aleks       0.806667     0.932809       1        aca   \n",
       "\n",
       "      name_b  partial  tkn_sort  tkn_set   sum_ipa  pshp_soundex_first  \\\n",
       "26   tabitha       75        29       29  0.774194                   0   \n",
       "45     aboli       71        42       42  0.403226                   0   \n",
       "67      bisi       75        53       57  0.322581                   0   \n",
       "72  abdollah       76        59       59  0.725806                   0   \n",
       "82     aleks       64        40       40  0.865591                   0   \n",
       "\n",
       "    iterativesubstring     bisim  discountedlevenshtein    prefix    lcsstr  \\\n",
       "26             0.00000  0.285714               0.335921  0.000000  0.285714   \n",
       "45             0.10000  0.444444               0.520491  0.400000  0.222222   \n",
       "67             0.69076  0.428571               0.472095  0.000000  0.428571   \n",
       "72             0.10000  0.500000               0.566334  0.400000  0.250000   \n",
       "82             0.05000  0.300000               0.233956  0.333333  0.200000   \n",
       "\n",
       "    mlipns  strcmp95  mra    editex      saps  flexmetric      jaro  \\\n",
       "26     0.0  0.634524  0.0  0.428571  0.000000    0.557143  0.595238   \n",
       "45     0.0  0.823407  0.0  0.555556  0.000000    0.583333  0.748148   \n",
       "67     0.0  0.765476  0.0  0.500000  0.185185    0.442857  0.726190   \n",
       "72     0.0  0.839333  0.5  0.687500  0.304348    0.787500  0.766667   \n",
       "82     0.0  0.617778  0.0  0.300000  0.000000    0.480000  0.511111   \n",
       "\n",
       "    higueramico     sift4     eudex     aline  covington  phoneticeditdistance  \n",
       "26     0.204762  0.285714  0.781373  0.364865   0.556604              0.529954  \n",
       "45     0.343254  0.444444  0.886765  0.442553   0.671642              0.551971  \n",
       "67     0.347619  0.428571  0.821078  0.560606   0.669811              0.552995  \n",
       "72     0.440476  0.500000  0.938235  0.529545   0.698413              0.608871  \n",
       "82     0.150000  0.200000  0.989216  0.259259   0.525641              0.512903  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ['a', 'b', 'name_a', 'name_b', 'target', 'predict_proba', 'siamese_sim']]\n",
    "comb2 = list(combinations(cols, 2))\n",
    "comb3 = list(combinations(cols, 3))\n",
    "colgrid = [(col,)for col in cols]+comb2+comb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring = 'precision', verbose=0)\n",
    "\n",
    "scores = []\n",
    "for cols in colgrid:\n",
    "    grid_clf.fit(X_train[['predict_proba', 'siamese_sim']+list(cols)], y_train)\n",
    "    y_pred = grid_clf.predict(X_val[['predict_proba', 'siamese_sim']+list(cols)])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    scores.append([str(cols), tn, fp, fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.columns = ['features', 'tn', 'fp', 'fn', 'tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('partial',)</td>\n",
       "      <td>13818</td>\n",
       "      <td>229</td>\n",
       "      <td>910</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('tkn_sort',)</td>\n",
       "      <td>13796</td>\n",
       "      <td>251</td>\n",
       "      <td>902</td>\n",
       "      <td>2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('tkn_set',)</td>\n",
       "      <td>13804</td>\n",
       "      <td>243</td>\n",
       "      <td>909</td>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('sum_ipa',)</td>\n",
       "      <td>13927</td>\n",
       "      <td>120</td>\n",
       "      <td>1239</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('pshp_soundex_first',)</td>\n",
       "      <td>14016</td>\n",
       "      <td>31</td>\n",
       "      <td>2347</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features     tn   fp    fn    tp\n",
       "0             ('partial',)  13818  229   910  2553\n",
       "1            ('tkn_sort',)  13796  251   902  2561\n",
       "2             ('tkn_set',)  13804  243   909  2554\n",
       "3             ('sum_ipa',)  13927  120  1239  2224\n",
       "4  ('pshp_soundex_first',)  14016   31  2347  1116"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['error'] = scores_df['fp'] + scores_df['fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.sort_values(['error', 'fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['predict_proba', 'siamese_sim', 'tkn_set', 'iterativesubstring', 'strcmp95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring='precision')\n",
    "grid_clf.fit(X_train[selected_cols], y_train)\n",
    "y_pred = grid_clf.predict(X_test[selected_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.0018329807108324356}\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix = pd.DataFrame(data=cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     14039\n",
      "           1       0.93      0.75      0.83      3471\n",
      "\n",
      "    accuracy                           0.94     17510\n",
      "   macro avg       0.93      0.87      0.90     17510\n",
      "weighted avg       0.94      0.94      0.94     17510\n",
      "\n",
      "           Predicted: 0  Predicted: 1\n",
      "Actual: 0         13828           211\n",
      "Actual: 1           851          2620\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.6, 0.3, 'AUC=0.961')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "baseline_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = grid_clf.predict_proba(X_test[selected_cols])\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "baseline_auc = roc_auc_score(y_test, baseline_probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "auc = ('AUC=%.3f' % (auc))\n",
    "\n",
    "# calculate roc curves\n",
    "baseline_fpr, baseline_tpr, _ = roc_curve(y_test, baseline_probs)\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "ax.plot(baseline_fpr, baseline_tpr, color='gray')\n",
    "ax.plot(fpr, tpr, marker='.', color='black')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('False Positive Rate',fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate',fontsize=12)\n",
    "ax.set_title('Receiver Operating Characteristic', fontsize=16)\n",
    "plt.text(.6, .3, auc, fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Models and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_1 = base_model_1(X.drop(['a', 'b', 'name_a', 'name_b'], 1), y, X_test=None, export=True)\n",
    "joblib.dump(base_1, filename='base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_2(X[['name_a', 'name_b']], y, X_test=None, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_clf.best_estimator_, filename='meta.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
